name: Database Backup

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'Type of backup'
        required: true
        default: 'full'
        type: choice
        options:
          - full
          - incremental
          - schema-only

jobs:
  backup:
    name: Backup Railway PostgreSQL
    runs-on: ubuntu-latest
    outputs:
      backup_type: ${{ steps.backup.outputs.backup_type }}
      backup_status: ${{ job.status }}
      backup_file: ${{ steps.backup.outputs.backup_file }}
      timestamp: ${{ steps.backup.outputs.timestamp }}
    env:
      RAILWAY_TOKEN: ${{ secrets.RAILWAY_TOKEN }}
      RAILWAY_PROJECT_ID: ${{ secrets.RAILWAY_PROJECT_ID }}
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_DEFAULT_REGION: ${{ secrets.AWS_REGION }}
      BACKUP_S3_BUCKET: ${{ secrets.BACKUP_S3_BUCKET }}
    
    steps:
      - uses: actions/checkout@v4

      - name: Validate Environment Variables
        run: |
          echo "üîç Validating required and optional environment variables..."

          # Check required secrets
          MISSING_REQUIRED=false

          if [ -z "$RAILWAY_TOKEN" ]; then
            echo "‚ùå RAILWAY_TOKEN is required but not set"
            MISSING_REQUIRED=true
          else
            echo "‚úÖ RAILWAY_TOKEN is configured"
          fi

          if [ -z "$RAILWAY_PROJECT_ID" ]; then
            echo "‚ùå RAILWAY_PROJECT_ID is required but not set"
            MISSING_REQUIRED=true
          else
            echo "‚úÖ RAILWAY_PROJECT_ID is configured"
          fi

          # Check optional secrets
          if [ -n "$AWS_ACCESS_KEY_ID" ] && [ -n "$AWS_SECRET_ACCESS_KEY" ] && [ -n "$BACKUP_S3_BUCKET" ]; then
            echo "‚úÖ AWS S3 backup is configured and will be used"
          else
            echo "‚ÑπÔ∏è AWS S3 backup is not fully configured (optional)"
            echo "   Missing one or more of: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, BACKUP_S3_BUCKET"
          fi

          if [ -n "$SLACK_WEBHOOK_URL" ]; then
            echo "‚úÖ Slack notifications are configured"
          else
            echo "‚ÑπÔ∏è Slack notifications are not configured (optional)"
          fi

          # Exit if required secrets are missing
          if [ "$MISSING_REQUIRED" = "true" ]; then
            echo ""
            echo "‚ùå Cannot proceed: Required secrets are missing"
            echo "Please configure the missing secrets in repository settings"
            exit 1
          fi

          echo ""
          echo "‚úÖ All required environment variables are configured"

      - name: Install Dependencies
        run: |
          # Install PostgreSQL client tools
          sudo apt-get update
          sudo apt-get install -y postgresql-client-15
          
          # Install Railway CLI
          npm install -g @railway/cli
          
          # Install AWS CLI for S3 backup storage (optional)
          pip install awscli
      
      - name: Get Database Credentials
        id: db-creds
        run: |
          # Validate required secrets
          if [ -z "$RAILWAY_TOKEN" ]; then
            echo "‚ùå RAILWAY_TOKEN secret is not configured"
            exit 1
          fi

          if [ -z "$RAILWAY_PROJECT_ID" ]; then
            echo "‚ùå RAILWAY_PROJECT_ID secret is not configured"
            exit 1
          fi

          railway link "$RAILWAY_PROJECT_ID"

          # Get database URL from Railway
          DB_URL=$(railway variables --service mdv-postgres --kv | grep DATABASE_URL | cut -d'=' -f2-)
          
          # Parse database URL
          DB_HOST=$(echo $DB_URL | sed -n 's/.*@\([^:]*\):.*/\1/p')
          DB_PORT=$(echo $DB_URL | sed -n 's/.*:\([0-9]*\)\/.*/\1/p')
          DB_NAME=$(echo $DB_URL | sed -n 's/.*\/\(.*\)/\1/p')
          DB_USER=$(echo $DB_URL | sed -n 's/.*:\/\/\([^:]*\):.*/\1/p')
          DB_PASS=$(echo $DB_URL | sed -n 's/.*:\/\/[^:]*:\([^@]*\)@.*/\1/p')
          
          echo "::add-mask::$DB_PASS"
          echo "db_host=$DB_HOST" >> $GITHUB_OUTPUT
          echo "db_port=$DB_PORT" >> $GITHUB_OUTPUT
          echo "db_name=$DB_NAME" >> $GITHUB_OUTPUT
          echo "db_user=$DB_USER" >> $GITHUB_OUTPUT
          echo "db_pass=$DB_PASS" >> $GITHUB_OUTPUT
      
      - name: Create Backup
        id: backup
        env:
          PGPASSWORD: ${{ steps.db-creds.outputs.db_pass }}
        run: |
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          BACKUP_TYPE="${{ github.event.inputs.backup_type || 'full' }}"
          BACKUP_FILE="mdv_backup_${BACKUP_TYPE}_${TIMESTAMP}.sql"
          
          echo "Creating $BACKUP_TYPE backup..."
          
          if [ "$BACKUP_TYPE" = "schema-only" ]; then
            pg_dump \
              -h ${{ steps.db-creds.outputs.db_host }} \
              -p ${{ steps.db-creds.outputs.db_port }} \
              -U ${{ steps.db-creds.outputs.db_user }} \
              -d ${{ steps.db-creds.outputs.db_name }} \
              --schema-only \
              --verbose \
              -f $BACKUP_FILE
          else
            pg_dump \
              -h ${{ steps.db-creds.outputs.db_host }} \
              -p ${{ steps.db-creds.outputs.db_port }} \
              -U ${{ steps.db-creds.outputs.db_user }} \
              -d ${{ steps.db-creds.outputs.db_name }} \
              --verbose \
              --format=custom \
              --blobs \
              -f $BACKUP_FILE
          fi
          
          # Compress the backup
          gzip $BACKUP_FILE
          BACKUP_FILE="${BACKUP_FILE}.gz"
          
          # Get file size
          FILE_SIZE=$(du -h $BACKUP_FILE | cut -f1)
          
          echo "backup_file=$BACKUP_FILE" >> $GITHUB_OUTPUT
          echo "file_size=$FILE_SIZE" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
          echo "backup_type=$BACKUP_TYPE" >> $GITHUB_OUTPUT
      
      - name: Upload to GitHub Artifacts
        uses: actions/upload-artifact@v3
        with:
          name: database-backup-${{ steps.backup.outputs.timestamp }}
          path: ${{ steps.backup.outputs.backup_file }}
          retention-days: 30
      
      - name: Upload to S3 (Optional)
        if: ${{ env.AWS_ACCESS_KEY_ID != '' && env.AWS_SECRET_ACCESS_KEY != '' && env.BACKUP_S3_BUCKET != '' }}
        run: |
          echo "üîÑ Uploading backup to S3..."
          S3_BUCKET="$BACKUP_S3_BUCKET"
          S3_PATH="database-backups/railway/${{ steps.backup.outputs.backup_file }}"

          echo "S3 Bucket: $S3_BUCKET"
          echo "S3 Path: $S3_PATH"

          # Upload to S3
          if aws s3 cp "${{ steps.backup.outputs.backup_file }}" "s3://$S3_BUCKET/$S3_PATH"; then
            echo "‚úÖ Backup successfully uploaded to S3"

            # Set lifecycle for old backups (keep last 30 days)
            aws s3api put-object-tagging \
              --bucket "$S3_BUCKET" \
              --key "$S3_PATH" \
              --tagging 'TagSet=[{Key=AutoDelete,Value=30days}]' || echo "‚ö†Ô∏è Failed to set S3 object tags (non-critical)"
          else
            echo "‚ùå Failed to upload backup to S3"
            exit 1
          fi
      
      - name: Verify Backup Integrity
        env:
          PGPASSWORD: ${{ steps.db-creds.outputs.db_pass }}
        run: |
          echo "Verifying backup integrity..."
          
          # For custom format backups, list contents
          if [ "${{ steps.backup.outputs.backup_type }}" != "schema-only" ]; then
            gunzip -c ${{ steps.backup.outputs.backup_file }} | pg_restore -l > /dev/null 2>&1
            if [ $? -eq 0 ]; then
              echo "‚úÖ Backup integrity verified"
            else
              echo "‚ùå Backup integrity check failed"
              exit 1
            fi
          fi
      
      - name: Clean Up Old Backups
        continue-on-error: true
        run: |
          # Clean up artifacts older than 30 days (handled by retention-days)
          echo "Old backups will be automatically cleaned up based on retention policy"
      
      - name: Backup Summary
        if: always()
        run: |
          echo "## üíæ Database Backup Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Backup Details:" >> $GITHUB_STEP_SUMMARY
          echo "- **Type**: ${{ steps.backup.outputs.backup_type }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: ${{ steps.backup.outputs.timestamp }}" >> $GITHUB_STEP_SUMMARY
          echo "- **File**: ${{ steps.backup.outputs.backup_file }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Size**: ${{ steps.backup.outputs.file_size }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Storage Locations:" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ GitHub Artifacts (30 days retention)" >> $GITHUB_STEP_SUMMARY
          if [ -n "$BACKUP_S3_BUCKET" ]; then
            echo "- ‚úÖ AWS S3: $BACKUP_S3_BUCKET" >> $GITHUB_STEP_SUMMARY
          fi

  # Notification job
  notify:
    name: Send Backup Notification
    needs: backup
    if: always()
    runs-on: ubuntu-latest
    env:
      SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
    
    steps:
      - name: Send Notification
        if: ${{ env.SLACK_WEBHOOK_URL != '' }}
        run: |
          echo "üì¢ Sending backup notification to Slack..."
          STATUS_EMOJI=$([[ "${{ needs.backup.result }}" == "success" ]] && echo "‚úÖ" || echo "‚ùå")

          # Prepare notification payload
          NOTIFICATION_PAYLOAD='{
            "text": "'"$STATUS_EMOJI"' Database Backup: '"${{ needs.backup.result }}"'",
            "blocks": [
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*Database Backup Completed*\n*Status:* '"${{ needs.backup.result }}"'\n*Type:* '"${{ needs.backup.outputs.backup_type }}"'\n*File:* '"${{ needs.backup.outputs.backup_file }}"'\n*Timestamp:* '"${{ needs.backup.outputs.timestamp }}"'"
                }
              }
            ]
          }'

          # Send notification with error handling
          if curl -X POST "$SLACK_WEBHOOK_URL" \
            -H 'Content-Type: application/json' \
            -d "$NOTIFICATION_PAYLOAD" \
            --fail --silent --show-error; then
            echo "‚úÖ Notification sent successfully to Slack"
          else
            echo "‚ùå Failed to send notification to Slack"
            echo "Webhook URL configured but request failed"
            exit 1
          fi

      - name: Notification Fallback
        if: ${{ env.SLACK_WEBHOOK_URL == '' }}
        run: |
          echo "‚ÑπÔ∏è Slack webhook not configured - skipping notification"
          echo "Backup completed with status: ${{ needs.backup.result }}"
          echo "Backup type: ${{ needs.backup.outputs.backup_type }}"
          echo "Backup file: ${{ needs.backup.outputs.backup_file }}"
